{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98a29fe",
   "metadata": {},
   "source": [
    "# Exploratory data analysis 1\n",
    "\n",
    "**INPUT**: Stratified train, validation corpora\n",
    "\n",
    "**OUTPUT**: Preprocessing decisions\n",
    "\n",
    "| Step | Decision | Status | Comment |\n",
    "|------|----------|--------|---------|\n",
    "| Message length distribution | Remove outliers | Done | Use the 1.5xIQR (John Tukey) rule, lower is minus, add one manually |\n",
    "| Vocabulary size estimation | Between 16-32k | Pending | For lstm start with low, llm can work with greater, read for heuristics |\n",
    "| OOV rate estimation | Find patterns to replace | Pending | Chosen patterns: url, email, phone, uppercase. Have to fine tune regex patterns & normalize email and urls. \n",
    "| Repeated chars | Collapse them | Pending | Same char appearing > 3 times. Collapse them to unified 2 chars |\n",
    "| Special chars | Keep some | Pending | Maybe ! ? % $ are meaningful keep them? Ask Consultant |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c1f74",
   "metadata": {},
   "source": [
    "## Input & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8664c2",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c558c5",
   "metadata": {},
   "source": [
    "### Read train corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29337b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path.cwd().parent\n",
    "train_path = root / \"data\" / \"corpora\" / \"raw\" / \"train_raw.csv\"\n",
    "validation_path = root / \"data\" / \"corpora\" / \"raw\" / \"validation_raw.csv\"\n",
    "train = pd.read_csv(train_path)\n",
    "validation = pd.read_csv(validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29b05f",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aee96e",
   "metadata": {},
   "source": [
    "### Message length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_lengths = train[\"Message\"].str.len()\n",
    "char_length_statistics = msg_lengths.describe()\n",
    "\n",
    "spam_msg_lengths = train[train['Spam/Ham'] == 'spam']['Message'].str.len()\n",
    "spam_char_lengths_statistics = spam_msg_lengths.describe()\n",
    "\n",
    "ham_msg_lengths = train[train['Spam/Ham'] == 'ham']['Message'].str.len()    \n",
    "ham_char_lengths_statistics =ham_msg_lengths.describe()\n",
    "\n",
    "print(char_length_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4103c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(ham_msg_lengths, bins=50)\n",
    "plt.hist(spam_msg_lengths, bins=50)\n",
    "plt.xlabel(\"Message length (characters)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Message Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = char_length_statistics['25%']\n",
    "q3 = char_length_statistics['75%']\n",
    "\n",
    "def calculate_scaled_IQR(q1, q3, scaling_factor = 1.5):\n",
    "    IQR = q3 -q1\n",
    "    upper_boundary = int(q3 + scaling_factor*IQR)\n",
    "    lower_boundary = int(q1 - scaling_factor*IQR)\n",
    "    return upper_boundary, lower_boundary\n",
    "\n",
    "upper, lower = calculate_scaled_IQR(q1,q3)\n",
    "print(upper)\n",
    "print(lower)\n",
    "\n",
    "lower = 20 # Own decision\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff4e2a",
   "metadata": {},
   "source": [
    "### Vocabulary size estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_tokens_train_set = train['Message'].astype(str).str.split()\n",
    "vocab = set(token for msg in estimated_tokens_train_set for token in msg)\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "list(vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f8677",
   "metadata": {},
   "source": [
    "### Out of vocabulary rate (OOV) estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0783554",
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_tokens = 0\n",
    "\n",
    "estimated_tokens_validation_set = validation['Message'].astype(str).str.split()\n",
    "\n",
    "for message in estimated_tokens_validation_set:\n",
    "    for token in message:\n",
    "        if token not in vocab:\n",
    "            oov_tokens += 1\n",
    "\n",
    "oov_rate = oov_tokens / vocab_size\n",
    "print(oov_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd4fec",
   "metadata": {},
   "source": [
    "### Patterns to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d60b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: revise regex after normalized URLs and EMAILs (they contain spaces)\n",
    "regex_url = r'^https?://(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&//=]*)$'\n",
    "regex_email = r'\\b[a-zA-Z0-9](?:[a-zA-Z0-9._-]*[a-zA-Z0-9])?@[a-zA-Z0-9](?:[a-zA-Z0-9.-]*[a-zA-Z0-9])?\\.[a-zA-Z]{2,}\\b'\n",
    "# TODO: revise regex for phone, is it useale? Or leave only num?\n",
    "regex_phone = r'\\b(?:\\+?1[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
    "regex_num = r'\\b\\d+(?:\\.\\d+)?\\b'\n",
    "regex_uppercase = r'\\b[a-z]*[A-Z]+[a-z]*[A-Z]+[a-z]*\\b'\n",
    "regex_repeated_char = r'(.)\\1{2,}'\n",
    "num_of_urls = train['Message'].str.count(regex_url).sum()\n",
    "num_of_emails = train['Message'].str.count(regex_email).sum()\n",
    "num_of_phone_numbers = train['Message'].str.count(regex_phone).sum()\n",
    "num_of_numbers = train['Message'].str.count(regex_num).sum()\n",
    "num_of_uppercase_words = train['Message'].str.count(regex_uppercase).sum()\n",
    "repeated_char_count = num_of_urls = train['Message'].str.count(regex_repeated_char).sum()\n",
    "print(num_of_urls)\n",
    "print(num_of_emails)\n",
    "print(num_of_phone_numbers)\n",
    "print(num_of_numbers)\n",
    "print(num_of_uppercase_words)\n",
    "print(repeated_char_count)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
