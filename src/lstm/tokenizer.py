
class SentencePieceTokenizer:
    def __init__(self, model_path):
        pass

    def encode(self, text):
        pass
    def decode(self, token_ids):
        pass

    def encode_batch(
        self,
        texts,
        padding,
        truncation,
        return_lengths):
        pass

    def get_vocab_size(self):
        pass